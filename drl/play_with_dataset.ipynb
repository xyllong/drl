{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d3rlpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from d3rlpy.dataset import Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_transitions(dataset,):\n",
    "    rets = []\n",
    "    num_data = dataset['observations'].shape[0]\n",
    "    observation_shape = dataset['observations'][0].shape\n",
    "    action_size = dataset['actions'][0].shape[0]\n",
    "    for i in range(num_data):\n",
    "        transition = Transition(\n",
    "            observation_shape=observation_shape,\n",
    "            action_size=action_size,\n",
    "            observation=dataset['observations'][i],\n",
    "            action=dataset['actions'][i],\n",
    "            reward=dataset['rewards'][i],\n",
    "            next_observation=dataset['next_observations'][i],\n",
    "            terminal=dataset['terminals'][i],\n",
    "        )\n",
    "\n",
    "        # set pointer to the next transition\n",
    "        rets.append(transition)\n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dictionary(list_of_dict):\n",
    "    merged_data = {}\n",
    "\n",
    "    for d in list_of_dict:\n",
    "        for k, v in d.items():\n",
    "            if k not in merged_data.keys():\n",
    "                merged_data[k] = [v]\n",
    "            else:\n",
    "                merged_data[k].append(v)\n",
    "\n",
    "    for k, v in merged_data.items():\n",
    "        merged_data[k] = np.concatenate(merged_data[k])\n",
    "\n",
    "    return merged_data\n",
    "dataset_name = 'halfcheetah-medium-replay-v0'\n",
    "data = np.load(f'./gta/{dataset_name}.npz', allow_pickle=True)\n",
    "config_dict = data['config'].item()\n",
    "dataset = data['data'].squeeze()\n",
    "\n",
    "metadata = {}\n",
    "\n",
    "metadata['diffusion_horizon'] = config_dict['construct_diffusion_model']['denoising_network']['horizon']\n",
    "metadata['diffusion_backbone'] = config_dict['construct_diffusion_model']['denoising_network']['_target_'].split('.')[-1]\n",
    "metadata['conditioned'] = True if config_dict['construct_diffusion_model']['denoising_network']['cond_dim'] != 0 else False\n",
    "metadata['guidance_target_multiple'] = config_dict['SimpleDiffusionGenerator']['amplify_returnscale']\n",
    "metadata['noise_level'] = config_dict['SimpleDiffusionGenerator']['noise_level']\n",
    "dataset = merge_dictionary([*dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transition_list \u001b[38;5;241m=\u001b[39m _to_transitions(\u001b[43mdataset\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "transition_list = _to_transitions(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\n",
    "    f'./gta/{dataset_name}-dataset.npz', \n",
    "    observations=dataset['observations'],\n",
    "    actions=dataset['actions'],\n",
    "    rewards=dataset['rewards'],\n",
    "    next_observations=dataset['next_observations'],\n",
    "    terminals=dataset['terminals'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'halfcheetah-medium-replay-v0'\n",
    "test = np.load(f'./gta/{dataset_name}-dataset.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = d3rlpy.datasets.get_d4rl('halfcheetah-medium-replay-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = ['halfcheetah-medium-replay-v0', 'hopper-medium-replay-v0', 'walker2d-medium-replay-v0']\n",
    "datasets = [d3rlpy.datasets.get_d4rl(exp)[0] for exp in exps]\n",
    "exp_datasets = dict(zip(exps, datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[0].compute_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "for ax, (exp_name, dataset) in zip(axes,exp_datasets.items()):\n",
    "    episodes = dataset.episodes\n",
    "    returns = [episode.compute_return() for episode in episodes]\n",
    "    ax.plot(returns)\n",
    "    ax.set_title(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "encoder = d3rlpy.models.encoders.VectorEncoderFactory([256, 256, 256])\n",
    "\n",
    "exp_name, dataset = list(exp_datasets.items())[0]\n",
    "if \"medium-v0\" in exp_name:\n",
    "    conservative_weight = 10.0\n",
    "else:\n",
    "    conservative_weight = 5.0\n",
    "cql = d3rlpy.algos.CQL(actor_learning_rate=1e-4,\n",
    "                           critic_learning_rate=3e-4,\n",
    "                           temp_learning_rate=1e-4,\n",
    "                           actor_encoder_factory=encoder,\n",
    "                           critic_encoder_factory=encoder,\n",
    "                           batch_size=256,\n",
    "                           n_action_samples=10,\n",
    "                           alpha_learning_rate=0.0,\n",
    "                           conservative_weight=conservative_weight,\n",
    "                           use_gpu=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cql.build_with_dataset(dataset)\n",
    "cql.load_model('../d3rlpy_logs/CQL_halfcheetah-medium-replay-v0_1_trim00_20240529201518/model_190000.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(21, 5, figsize=(20, 20))\n",
    "for i, episode in enumerate(dataset.episodes):\n",
    "    qs = cql.predict_value(episode.observations, episode.actions)\n",
    "    axes[i // 5][i % 5].plot(qs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
